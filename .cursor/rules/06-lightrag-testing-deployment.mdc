---
description: LightRAG æµ‹è¯•ä¸éƒ¨ç½²è§„åˆ™
alwaysApply: false
---
# LightRAG æµ‹è¯•ä¸éƒ¨ç½²è§„åˆ™

## ğŸ§ª æµ‹è¯•æ¶æ„æ¦‚è§ˆ

LightRAGé‡‡ç”¨å¤šå±‚æµ‹è¯•ç­–ç•¥ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•ï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“‚ æµ‹è¯•é¡¹ç›®ç»“æ„

```
tests/
â”œâ”€â”€ unit/                       # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_storage.py        # å­˜å‚¨å±‚æµ‹è¯•
â”‚   â”œâ”€â”€ test_llm.py            # LLMå±‚æµ‹è¯•
â”‚   â”œâ”€â”€ test_graph.py          # å›¾æ“ä½œæµ‹è¯•
â”‚   â””â”€â”€ test_utils.py          # å·¥å…·å‡½æ•°æµ‹è¯•
â”œâ”€â”€ integration/                # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_api.py            # APIé›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_pipeline.py       # å¤„ç†ç®¡é“æµ‹è¯•
â”‚   â””â”€â”€ test_retrieval.py      # æ£€ç´¢åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ performance/                # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_scalability.py    # å¯æ‰©å±•æ€§æµ‹è¯•
â”‚   â”œâ”€â”€ test_concurrent.py     # å¹¶å‘æ€§èƒ½æµ‹è¯•
â”‚   â””â”€â”€ test_memory.py         # å†…å­˜ä½¿ç”¨æµ‹è¯•
â”œâ”€â”€ e2e/                       # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_workflow.py       # å®Œæ•´å·¥ä½œæµæµ‹è¯•
â”‚   â””â”€â”€ test_user_scenarios.py # ç”¨æˆ·åœºæ™¯æµ‹è¯•
â”œâ”€â”€ fixtures/                   # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ documents/             # æµ‹è¯•æ–‡æ¡£
â”‚   â””â”€â”€ expected_outputs/      # æœŸæœ›è¾“å‡º
â””â”€â”€ conftest.py                # pytesté…ç½®
```

## ğŸ”§ æµ‹è¯•å¼€å‘è§„èŒƒ

### 1. å•å…ƒæµ‹è¯•è§„èŒƒ
```python
# tests/unit/test_storage.py
import pytest
import asyncio
from unittest.mock import AsyncMock, patch
from lightrag.kg.redis_impl import RedisKVStorage
from lightrag.kg.neo4j_impl import Neo4JStorage

@pytest.mark.asyncio
class TestRedisKVStorage:
    """Redis KVå­˜å‚¨å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    async def redis_storage(self):
        """Rediså­˜å‚¨æµ‹è¯•å¤¹å…·"""
        storage = RedisKVStorage("redis://localhost:6379/15")  # æµ‹è¯•æ•°æ®åº“
        await storage.connect()
        yield storage
        await storage.disconnect()
        
    async def test_set_and_get(self, redis_storage):
        """æµ‹è¯•è®¾ç½®å’Œè·å–åŠŸèƒ½"""
        key = "test_key_123"
        value = "test_value_456"
        
        # è®¾ç½®å€¼
        await redis_storage.set(key, value)
        
        # è·å–å€¼
        result = await redis_storage.get(key)
        assert result == value
        
        # æ¸…ç†
        await redis_storage.delete(key)
    
    async def test_key_not_exists(self, redis_storage):
        """æµ‹è¯•ä¸å­˜åœ¨çš„é”®"""
        result = await redis_storage.get("non_existent_key")
        assert result is None
    
    async def test_delete_functionality(self, redis_storage):
        """æµ‹è¯•åˆ é™¤åŠŸèƒ½"""
        key = "test_delete_key"
        value = "test_value"
        
        await redis_storage.set(key, value)
        assert await redis_storage.has(key) is True
        
        await redis_storage.delete(key)
        assert await redis_storage.has(key) is False

@pytest.mark.asyncio
class TestNeo4jStorage:
    """Neo4jå›¾å­˜å‚¨å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    async def neo4j_storage(self):
        """Neo4jå­˜å‚¨æµ‹è¯•å¤¹å…·"""
        storage = Neo4JStorage()
        await storage.connect()
        # æ¸…ç†æµ‹è¯•æ•°æ®
        await storage._execute_query("MATCH (n:TestNode) DETACH DELETE n")
        yield storage
        # æµ‹è¯•åæ¸…ç†
        await storage._execute_query("MATCH (n:TestNode) DETACH DELETE n")
        await storage.disconnect()
    
    async def test_add_node(self, neo4j_storage):
        """æµ‹è¯•æ·»åŠ èŠ‚ç‚¹"""
        node_id = "test_entity_123"
        node_data = {
            "name": "æµ‹è¯•å®ä½“",
            "type": "person",
            "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å®ä½“"
        }
        
        await neo4j_storage.add_node(node_id, node_data)
        
        # éªŒè¯èŠ‚ç‚¹æ˜¯å¦æ·»åŠ æˆåŠŸ
        result = await neo4j_storage._execute_query(
            "MATCH (n:Entity {id: $id}) RETURN n",
            id=node_id
        )
        assert len(result) == 1
        assert result[0]["n"]["name"] == "æµ‹è¯•å®ä½“"
```

### 2. é›†æˆæµ‹è¯•è§„èŒƒ
```python
# tests/integration/test_api.py
import pytest
import httpx
from fastapi.testclient import TestClient
from lightrag.api.lightrag_server import app

@pytest.fixture
def client():
    """APIæµ‹è¯•å®¢æˆ·ç«¯"""
    return TestClient(app)

@pytest.fixture
def auth_headers():
    """è®¤è¯å¤´ä¿¡æ¯"""
    return {"Authorization": "Bearer test-api-key"}

class TestDocumentAPI:
    """æ–‡æ¡£ç®¡ç†APIé›†æˆæµ‹è¯•"""
    
    def test_upload_document(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£ä¸Šä¼ """
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£å†…å®¹ã€‚åŒ…å«ä¸€äº›æµ‹è¯•å®ä½“å’Œå…³ç³»ã€‚"
        files = {"file": ("test.txt", test_content, "text/plain")}
        
        response = client.post(
            "/documents/upload",
            files=files,
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "id" in data
        
        return data["id"]  # è¿”å›æ–‡æ¡£IDä¾›å…¶ä»–æµ‹è¯•ä½¿ç”¨
    
    def test_list_documents(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£åˆ—è¡¨"""
        response = client.get("/documents", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)
    
    def test_delete_document(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£åˆ é™¤"""
        # å…ˆä¸Šä¼ ä¸€ä¸ªæ–‡æ¡£
        doc_id = self.test_upload_document(client, auth_headers)
        
        # åˆ é™¤æ–‡æ¡£
        response = client.delete(f"/documents/{doc_id}", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True

class TestQueryAPI:
    """æŸ¥è¯¢APIé›†æˆæµ‹è¯•"""
    
    def test_query_functionality(self, client, auth_headers):
        """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
        query_data = {
            "query": "æµ‹è¯•æŸ¥è¯¢é—®é¢˜",
            "mode": "hybrid"
        }
        
        response = client.post(
            "/query",
            json=query_data,
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "result" in data
        assert "metadata" in data
        assert data["metadata"]["mode"] == "hybrid"
    
    @pytest.mark.asyncio
    async def test_stream_query(self, auth_headers):
        """æµ‹è¯•æµå¼æŸ¥è¯¢"""
        query_data = {
            "query": "æµ‹è¯•æµå¼æŸ¥è¯¢",
            "mode": "local",
            "stream": True
        }
        
        async with httpx.AsyncClient(app=app, base_url="http://test") as client:
            async with client.stream(
                "POST",
                "/query/stream",
                json=query_data,
                headers=auth_headers
            ) as response:
                assert response.status_code == 200
                
                chunks = []
                async for chunk in response.aiter_text():
                    if chunk.strip():
                        chunks.append(chunk)
                
                assert len(chunks) > 0
```

### 3. æ€§èƒ½æµ‹è¯•è§„èŒƒ
```python
# tests/performance/test_concurrent.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from lightrag import LightRAG

@pytest.mark.performance
class TestConcurrentPerformance:
    """å¹¶å‘æ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture
    async def lightrag_instance(self):
        """LightRAGå®ä¾‹"""
        rag = LightRAG(
            working_dir="./test_rag_storage",
            # ä½¿ç”¨æµ‹è¯•é…ç½®
        )
        yield rag
        # æ¸…ç†æµ‹è¯•æ•°æ®
        
    async def test_concurrent_queries(self, lightrag_instance):
        """æµ‹è¯•å¹¶å‘æŸ¥è¯¢æ€§èƒ½"""
        queries = [
            "æµ‹è¯•æŸ¥è¯¢1",
            "æµ‹è¯•æŸ¥è¯¢2", 
            "æµ‹è¯•æŸ¥è¯¢3",
            "æµ‹è¯•æŸ¥è¯¢4",
            "æµ‹è¯•æŸ¥è¯¢5"
        ] * 20  # 100ä¸ªæŸ¥è¯¢
        
        start_time = time.time()
        
        # å¹¶å‘æ‰§è¡ŒæŸ¥è¯¢
        tasks = [
            lightrag_instance.aquery(query, mode="hybrid")
            for query in queries
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€
        assert total_time < 60  # 100ä¸ªæŸ¥è¯¢åº”è¯¥åœ¨60ç§’å†…å®Œæˆ
        
        # æ£€æŸ¥é”™è¯¯ç‡
        errors = [r for r in results if isinstance(r, Exception)]
        error_rate = len(errors) / len(results)
        assert error_rate < 0.05  # é”™è¯¯ç‡åº”è¯¥å°äº5%
        
        print(f"å¹¶å‘æŸ¥è¯¢æ€§èƒ½: {len(queries)}ä¸ªæŸ¥è¯¢, æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"å¹³å‡å“åº”æ—¶é—´: {total_time/len(queries):.3f}ç§’")
        print(f"é”™è¯¯ç‡: {error_rate:.2%}")
    
    async def test_document_processing_performance(self, lightrag_instance):
        """æµ‹è¯•æ–‡æ¡£å¤„ç†æ€§èƒ½"""
        # åˆ›å»ºå¤§å‹æµ‹è¯•æ–‡æ¡£
        large_document = "è¿™æ˜¯ä¸€ä¸ªå¤§å‹æµ‹è¯•æ–‡æ¡£ã€‚" * 10000  # çº¦20ä¸‡å­—ç¬¦
        
        start_time = time.time()
        
        await lightrag_instance.ainsert(large_document)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€
        assert processing_time < 300  # å¤§æ–‡æ¡£å¤„ç†åº”è¯¥åœ¨5åˆ†é’Ÿå†…å®Œæˆ
        
        print(f"æ–‡æ¡£å¤„ç†æ€§èƒ½: {len(large_document)}å­—ç¬¦, å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
```

## ğŸš€ éƒ¨ç½²é…ç½®

### 1. Dockeréƒ¨ç½²
```dockerfile
# Dockerfile
FROM python:3.10-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY pyproject.toml .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir -e .

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/rag_storage /app/logs /app/inputs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV WORKING_DIR=/app/rag_storage
ENV LOG_DIR=/app/logs

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "lightrag.api.lightrag_server"]
```

### 2. Docker Composeé…ç½®
```yaml
# docker-compose.yml
version: '3.8'

services:
  lightrag:
    build: .
    ports:
      - "8000:8000"
    environment:
      # ä»ç”¨æˆ·é…ç½®è¯»å–ç¯å¢ƒå˜é‡
      - HOST=0.0.0.0
      - PORT=8000
      - WEBUI_TITLE=æˆ‘çš„å›¾è°±çŸ¥è¯†åº“
      - LOG_LEVEL=INFO
      
      # æ•°æ®åº“è¿æ¥
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=lightrag123
      - POSTGRES_DATABASE=lightrag_db
      
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=neo4j123
      
      - REDIS_URI=redis://redis:6379/0
      
      # LLMé…ç½®
      - LLM_BINDING=siliconflow
      - LLM_MODEL=Qwen/Qwen2.5-14B-Instruct
      - LLM_BINDING_API_KEY=${SILICONFLOW_API_KEY}
    volumes:
      - ./rag_storage:/app/rag_storage
      - ./logs:/app/logs
      - ./inputs:/app/inputs
    depends_on:
      postgres:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  postgres:
    image: pgvector/pgvector:pg16
    environment:
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=lightrag123
      - POSTGRES_DB=lightrag_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lightrag -d lightrag_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  neo4j:
    image: neo4j:5.15
    environment:
      - NEO4J_AUTH=neo4j/neo4j123
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    ports:
      - "7474:7474"
      - "7687:7687"
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p neo4j123 'RETURN 1'"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

volumes:
  postgres_data:
  neo4j_data:
  neo4j_logs:
  redis_data:
```

### 3. Kuberneteséƒ¨ç½²
```yaml
# k8s-deploy/lightrag/values.yaml
# æ ¹æ®ç”¨æˆ·é…ç½®çš„Kuberneteséƒ¨ç½²é…ç½®
replicaCount: 2

image:
  repository: lightrag/lightrag
  tag: "latest"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: lightrag.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: lightrag-tls
      hosts:
        - lightrag.example.com

env:
  # ä»ç”¨æˆ·é…ç½®æ˜ å°„ç¯å¢ƒå˜é‡
  HOST: "0.0.0.0"
  PORT: "8000"
  WEBUI_TITLE: "æˆ‘çš„å›¾è°±çŸ¥è¯†åº“"
  
  # æ•°æ®åº“è¿æ¥(KubernetesæœåŠ¡å)
  POSTGRES_HOST: "postgresql"
  NEO4J_URI: "bolt://neo4j:7687"
  REDIS_URI: "redis://redis-master:6379/0"

persistence:
  enabled: true
  size: 10Gi
  storageClass: "fast-ssd"

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 1Gi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

# æ•°æ®åº“ä¾èµ–
postgresql:
  enabled: true
  auth:
    postgresPassword: "lightrag123"
    database: "lightrag_db"

neo4j:
  enabled: true
  auth:
    password: "neo4j123"

redis:
  enabled: true
  auth:
    enabled: false
```

## ğŸ” ç›‘æ§å’Œè¿ç»´

### 1. å¥åº·æ£€æŸ¥é…ç½®
```python
# lightrag/api/health.py
from fastapi import APIRouter, HTTPException
from lightrag.kg.shared_storage import StorageManager

router = APIRouter()

@router.get("/health")
async def health_check():
    """åŸºç¡€å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@router.get("/health/detailed")
async def detailed_health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "services": {}
    }
    
    # æ£€æŸ¥å­˜å‚¨æœåŠ¡
    storage_manager = StorageManager()
    
    try:
        # Redisè¿æ¥æ£€æŸ¥
        await storage_manager.kv_storage.get("health_check")
        health_status["services"]["redis"] = "healthy"
    except Exception as e:
        health_status["services"]["redis"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    try:
        # PostgreSQLè¿æ¥æ£€æŸ¥
        await storage_manager.vector_storage.health_check()
        health_status["services"]["postgresql"] = "healthy"
    except Exception as e:
        health_status["services"]["postgresql"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    try:
        # Neo4jè¿æ¥æ£€æŸ¥
        await storage_manager.graph_storage.health_check()
        health_status["services"]["neo4j"] = "healthy"
    except Exception as e:
        health_status["services"]["neo4j"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    return health_status
```

### 2. æ—¥å¿—é…ç½®
```python
# lightrag/utils/logging.py
import logging
import os
from logging.handlers import RotatingFileHandler

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
    log_dir = os.getenv('LOG_DIR', './logs')
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(),
            # æ–‡ä»¶è¾“å‡º(è½®è½¬)
            RotatingFileHandler(
                os.path.join(log_dir, 'lightrag.log'),
                maxBytes=int(os.getenv('LOG_MAX_BYTES', 52428800)),  # 50MB
                backupCount=int(os.getenv('LOG_BACKUP_COUNT', 10))
            )
        ]
    )
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æµ‹è¯•æ•°æ®éš”ç¦»**: ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®åº“å’Œå­˜å‚¨
2. **æ€§èƒ½åŸºå‡†**: å»ºç«‹æ€§èƒ½åŸºå‡†çº¿ï¼Œç›‘æ§æ€§èƒ½å›å½’
3. **èµ„æºé™åˆ¶**: åœ¨å®¹å™¨ä¸­è®¾ç½®åˆé€‚çš„èµ„æºé™åˆ¶
4. **å®‰å…¨é…ç½®**: ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨å¼ºå¯†ç å’ŒSSLè¯ä¹¦
5. **æ•°æ®å¤‡ä»½**: é…ç½®å®šæœŸæ•°æ®å¤‡ä»½ç­–ç•¥
6. **ç›‘æ§å‘Šè­¦**: è®¾ç½®å…³é”®æŒ‡æ ‡çš„ç›‘æ§å’Œå‘Šè­¦
7. **æ—¥å¿—ç®¡ç†**: é…ç½®æ—¥å¿—è½®è½¬å’Œä¸­å¤®åŒ–æ—¥å¿—æ”¶é›†
---
# LightRAG æµ‹è¯•ä¸éƒ¨ç½²è§„åˆ™

## ğŸ§ª æµ‹è¯•æ¶æ„æ¦‚è§ˆ

LightRAGé‡‡ç”¨å¤šå±‚æµ‹è¯•ç­–ç•¥ï¼ŒåŒ…æ‹¬å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ€§èƒ½æµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•ï¼Œç¡®ä¿ç³»ç»Ÿçš„å¯é æ€§å’Œç¨³å®šæ€§ã€‚

## ğŸ“‚ æµ‹è¯•é¡¹ç›®ç»“æ„

```
tests/
â”œâ”€â”€ unit/                       # å•å…ƒæµ‹è¯•
â”‚   â”œâ”€â”€ test_storage.py        # å­˜å‚¨å±‚æµ‹è¯•
â”‚   â”œâ”€â”€ test_llm.py            # LLMå±‚æµ‹è¯•
â”‚   â”œâ”€â”€ test_graph.py          # å›¾æ“ä½œæµ‹è¯•
â”‚   â””â”€â”€ test_utils.py          # å·¥å…·å‡½æ•°æµ‹è¯•
â”œâ”€â”€ integration/                # é›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_api.py            # APIé›†æˆæµ‹è¯•
â”‚   â”œâ”€â”€ test_pipeline.py       # å¤„ç†ç®¡é“æµ‹è¯•
â”‚   â””â”€â”€ test_retrieval.py      # æ£€ç´¢åŠŸèƒ½æµ‹è¯•
â”œâ”€â”€ performance/                # æ€§èƒ½æµ‹è¯•
â”‚   â”œâ”€â”€ test_scalability.py    # å¯æ‰©å±•æ€§æµ‹è¯•
â”‚   â”œâ”€â”€ test_concurrent.py     # å¹¶å‘æ€§èƒ½æµ‹è¯•
â”‚   â””â”€â”€ test_memory.py         # å†…å­˜ä½¿ç”¨æµ‹è¯•
â”œâ”€â”€ e2e/                       # ç«¯åˆ°ç«¯æµ‹è¯•
â”‚   â”œâ”€â”€ test_workflow.py       # å®Œæ•´å·¥ä½œæµæµ‹è¯•
â”‚   â””â”€â”€ test_user_scenarios.py # ç”¨æˆ·åœºæ™¯æµ‹è¯•
â”œâ”€â”€ fixtures/                   # æµ‹è¯•æ•°æ®
â”‚   â”œâ”€â”€ documents/             # æµ‹è¯•æ–‡æ¡£
â”‚   â””â”€â”€ expected_outputs/      # æœŸæœ›è¾“å‡º
â””â”€â”€ conftest.py                # pytesté…ç½®
```

## ğŸ”§ æµ‹è¯•å¼€å‘è§„èŒƒ

### 1. å•å…ƒæµ‹è¯•è§„èŒƒ
```python
# tests/unit/test_storage.py
import pytest
import asyncio
from unittest.mock import AsyncMock, patch
from lightrag.kg.redis_impl import RedisKVStorage
from lightrag.kg.neo4j_impl import Neo4JStorage

@pytest.mark.asyncio
class TestRedisKVStorage:
    """Redis KVå­˜å‚¨å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    async def redis_storage(self):
        """Rediså­˜å‚¨æµ‹è¯•å¤¹å…·"""
        storage = RedisKVStorage("redis://localhost:6379/15")  # æµ‹è¯•æ•°æ®åº“
        await storage.connect()
        yield storage
        await storage.disconnect()
        
    async def test_set_and_get(self, redis_storage):
        """æµ‹è¯•è®¾ç½®å’Œè·å–åŠŸèƒ½"""
        key = "test_key_123"
        value = "test_value_456"
        
        # è®¾ç½®å€¼
        await redis_storage.set(key, value)
        
        # è·å–å€¼
        result = await redis_storage.get(key)
        assert result == value
        
        # æ¸…ç†
        await redis_storage.delete(key)
    
    async def test_key_not_exists(self, redis_storage):
        """æµ‹è¯•ä¸å­˜åœ¨çš„é”®"""
        result = await redis_storage.get("non_existent_key")
        assert result is None
    
    async def test_delete_functionality(self, redis_storage):
        """æµ‹è¯•åˆ é™¤åŠŸèƒ½"""
        key = "test_delete_key"
        value = "test_value"
        
        await redis_storage.set(key, value)
        assert await redis_storage.has(key) is True
        
        await redis_storage.delete(key)
        assert await redis_storage.has(key) is False

@pytest.mark.asyncio
class TestNeo4jStorage:
    """Neo4jå›¾å­˜å‚¨å•å…ƒæµ‹è¯•"""
    
    @pytest.fixture
    async def neo4j_storage(self):
        """Neo4jå­˜å‚¨æµ‹è¯•å¤¹å…·"""
        storage = Neo4JStorage()
        await storage.connect()
        # æ¸…ç†æµ‹è¯•æ•°æ®
        await storage._execute_query("MATCH (n:TestNode) DETACH DELETE n")
        yield storage
        # æµ‹è¯•åæ¸…ç†
        await storage._execute_query("MATCH (n:TestNode) DETACH DELETE n")
        await storage.disconnect()
    
    async def test_add_node(self, neo4j_storage):
        """æµ‹è¯•æ·»åŠ èŠ‚ç‚¹"""
        node_id = "test_entity_123"
        node_data = {
            "name": "æµ‹è¯•å®ä½“",
            "type": "person",
            "description": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å®ä½“"
        }
        
        await neo4j_storage.add_node(node_id, node_data)
        
        # éªŒè¯èŠ‚ç‚¹æ˜¯å¦æ·»åŠ æˆåŠŸ
        result = await neo4j_storage._execute_query(
            "MATCH (n:Entity {id: $id}) RETURN n",
            id=node_id
        )
        assert len(result) == 1
        assert result[0]["n"]["name"] == "æµ‹è¯•å®ä½“"
```

### 2. é›†æˆæµ‹è¯•è§„èŒƒ
```python
# tests/integration/test_api.py
import pytest
import httpx
from fastapi.testclient import TestClient
from lightrag.api.lightrag_server import app

@pytest.fixture
def client():
    """APIæµ‹è¯•å®¢æˆ·ç«¯"""
    return TestClient(app)

@pytest.fixture
def auth_headers():
    """è®¤è¯å¤´ä¿¡æ¯"""
    return {"Authorization": "Bearer test-api-key"}

class TestDocumentAPI:
    """æ–‡æ¡£ç®¡ç†APIé›†æˆæµ‹è¯•"""
    
    def test_upload_document(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£ä¸Šä¼ """
        # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
        test_content = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£å†…å®¹ã€‚åŒ…å«ä¸€äº›æµ‹è¯•å®ä½“å’Œå…³ç³»ã€‚"
        files = {"file": ("test.txt", test_content, "text/plain")}
        
        response = client.post(
            "/documents/upload",
            files=files,
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
        assert "id" in data
        
        return data["id"]  # è¿”å›æ–‡æ¡£IDä¾›å…¶ä»–æµ‹è¯•ä½¿ç”¨
    
    def test_list_documents(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£åˆ—è¡¨"""
        response = client.get("/documents", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert isinstance(data, list)
    
    def test_delete_document(self, client, auth_headers):
        """æµ‹è¯•æ–‡æ¡£åˆ é™¤"""
        # å…ˆä¸Šä¼ ä¸€ä¸ªæ–‡æ¡£
        doc_id = self.test_upload_document(client, auth_headers)
        
        # åˆ é™¤æ–‡æ¡£
        response = client.delete(f"/documents/{doc_id}", headers=auth_headers)
        
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True

class TestQueryAPI:
    """æŸ¥è¯¢APIé›†æˆæµ‹è¯•"""
    
    def test_query_functionality(self, client, auth_headers):
        """æµ‹è¯•æŸ¥è¯¢åŠŸèƒ½"""
        query_data = {
            "query": "æµ‹è¯•æŸ¥è¯¢é—®é¢˜",
            "mode": "hybrid"
        }
        
        response = client.post(
            "/query",
            json=query_data,
            headers=auth_headers
        )
        
        assert response.status_code == 200
        data = response.json()
        assert "result" in data
        assert "metadata" in data
        assert data["metadata"]["mode"] == "hybrid"
    
    @pytest.mark.asyncio
    async def test_stream_query(self, auth_headers):
        """æµ‹è¯•æµå¼æŸ¥è¯¢"""
        query_data = {
            "query": "æµ‹è¯•æµå¼æŸ¥è¯¢",
            "mode": "local",
            "stream": True
        }
        
        async with httpx.AsyncClient(app=app, base_url="http://test") as client:
            async with client.stream(
                "POST",
                "/query/stream",
                json=query_data,
                headers=auth_headers
            ) as response:
                assert response.status_code == 200
                
                chunks = []
                async for chunk in response.aiter_text():
                    if chunk.strip():
                        chunks.append(chunk)
                
                assert len(chunks) > 0
```

### 3. æ€§èƒ½æµ‹è¯•è§„èŒƒ
```python
# tests/performance/test_concurrent.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from lightrag import LightRAG

@pytest.mark.performance
class TestConcurrentPerformance:
    """å¹¶å‘æ€§èƒ½æµ‹è¯•"""
    
    @pytest.fixture
    async def lightrag_instance(self):
        """LightRAGå®ä¾‹"""
        rag = LightRAG(
            working_dir="./test_rag_storage",
            # ä½¿ç”¨æµ‹è¯•é…ç½®
        )
        yield rag
        # æ¸…ç†æµ‹è¯•æ•°æ®
        
    async def test_concurrent_queries(self, lightrag_instance):
        """æµ‹è¯•å¹¶å‘æŸ¥è¯¢æ€§èƒ½"""
        queries = [
            "æµ‹è¯•æŸ¥è¯¢1",
            "æµ‹è¯•æŸ¥è¯¢2", 
            "æµ‹è¯•æŸ¥è¯¢3",
            "æµ‹è¯•æŸ¥è¯¢4",
            "æµ‹è¯•æŸ¥è¯¢5"
        ] * 20  # 100ä¸ªæŸ¥è¯¢
        
        start_time = time.time()
        
        # å¹¶å‘æ‰§è¡ŒæŸ¥è¯¢
        tasks = [
            lightrag_instance.aquery(query, mode="hybrid")
            for query in queries
        ]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = time.time()
        total_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€
        assert total_time < 60  # 100ä¸ªæŸ¥è¯¢åº”è¯¥åœ¨60ç§’å†…å®Œæˆ
        
        # æ£€æŸ¥é”™è¯¯ç‡
        errors = [r for r in results if isinstance(r, Exception)]
        error_rate = len(errors) / len(results)
        assert error_rate < 0.05  # é”™è¯¯ç‡åº”è¯¥å°äº5%
        
        print(f"å¹¶å‘æŸ¥è¯¢æ€§èƒ½: {len(queries)}ä¸ªæŸ¥è¯¢, æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"å¹³å‡å“åº”æ—¶é—´: {total_time/len(queries):.3f}ç§’")
        print(f"é”™è¯¯ç‡: {error_rate:.2%}")
    
    async def test_document_processing_performance(self, lightrag_instance):
        """æµ‹è¯•æ–‡æ¡£å¤„ç†æ€§èƒ½"""
        # åˆ›å»ºå¤§å‹æµ‹è¯•æ–‡æ¡£
        large_document = "è¿™æ˜¯ä¸€ä¸ªå¤§å‹æµ‹è¯•æ–‡æ¡£ã€‚" * 10000  # çº¦20ä¸‡å­—ç¬¦
        
        start_time = time.time()
        
        await lightrag_instance.ainsert(large_document)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        # æ€§èƒ½æ–­è¨€
        assert processing_time < 300  # å¤§æ–‡æ¡£å¤„ç†åº”è¯¥åœ¨5åˆ†é’Ÿå†…å®Œæˆ
        
        print(f"æ–‡æ¡£å¤„ç†æ€§èƒ½: {len(large_document)}å­—ç¬¦, å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’")
```

## ğŸš€ éƒ¨ç½²é…ç½®

### 1. Dockeréƒ¨ç½²
```dockerfile
# Dockerfile
FROM python:3.10-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    curl \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .
COPY pyproject.toml .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt
RUN pip install --no-cache-dir -e .

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºå¿…è¦çš„ç›®å½•
RUN mkdir -p /app/rag_storage /app/logs /app/inputs

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV WORKING_DIR=/app/rag_storage
ENV LOG_DIR=/app/logs

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "lightrag.api.lightrag_server"]
```

### 2. Docker Composeé…ç½®
```yaml
# docker-compose.yml
version: '3.8'

services:
  lightrag:
    build: .
    ports:
      - "8000:8000"
    environment:
      # ä»ç”¨æˆ·é…ç½®è¯»å–ç¯å¢ƒå˜é‡
      - HOST=0.0.0.0
      - PORT=8000
      - WEBUI_TITLE=æˆ‘çš„å›¾è°±çŸ¥è¯†åº“
      - LOG_LEVEL=INFO
      
      # æ•°æ®åº“è¿æ¥
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=lightrag123
      - POSTGRES_DATABASE=lightrag_db
      
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USERNAME=neo4j
      - NEO4J_PASSWORD=neo4j123
      
      - REDIS_URI=redis://redis:6379/0
      
      # LLMé…ç½®
      - LLM_BINDING=siliconflow
      - LLM_MODEL=Qwen/Qwen2.5-14B-Instruct
      - LLM_BINDING_API_KEY=${SILICONFLOW_API_KEY}
    volumes:
      - ./rag_storage:/app/rag_storage
      - ./logs:/app/logs
      - ./inputs:/app/inputs
    depends_on:
      postgres:
        condition: service_healthy
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped

  postgres:
    image: pgvector/pgvector:pg16
    environment:
      - POSTGRES_USER=lightrag
      - POSTGRES_PASSWORD=lightrag123
      - POSTGRES_DB=lightrag_db
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lightrag -d lightrag_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  neo4j:
    image: neo4j:5.15
    environment:
      - NEO4J_AUTH=neo4j/neo4j123
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    ports:
      - "7474:7474"
      - "7687:7687"
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p neo4j123 'RETURN 1'"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

volumes:
  postgres_data:
  neo4j_data:
  neo4j_logs:
  redis_data:
```

### 3. Kuberneteséƒ¨ç½²
```yaml
# k8s-deploy/lightrag/values.yaml
# æ ¹æ®ç”¨æˆ·é…ç½®çš„Kuberneteséƒ¨ç½²é…ç½®
replicaCount: 2

image:
  repository: lightrag/lightrag
  tag: "latest"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
  hosts:
    - host: lightrag.example.com
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: lightrag-tls
      hosts:
        - lightrag.example.com

env:
  # ä»ç”¨æˆ·é…ç½®æ˜ å°„ç¯å¢ƒå˜é‡
  HOST: "0.0.0.0"
  PORT: "8000"
  WEBUI_TITLE: "æˆ‘çš„å›¾è°±çŸ¥è¯†åº“"
  
  # æ•°æ®åº“è¿æ¥(KubernetesæœåŠ¡å)
  POSTGRES_HOST: "postgresql"
  NEO4J_URI: "bolt://neo4j:7687"
  REDIS_URI: "redis://redis-master:6379/0"

persistence:
  enabled: true
  size: 10Gi
  storageClass: "fast-ssd"

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 1Gi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

# æ•°æ®åº“ä¾èµ–
postgresql:
  enabled: true
  auth:
    postgresPassword: "lightrag123"
    database: "lightrag_db"

neo4j:
  enabled: true
  auth:
    password: "neo4j123"

redis:
  enabled: true
  auth:
    enabled: false
```

## ğŸ” ç›‘æ§å’Œè¿ç»´

### 1. å¥åº·æ£€æŸ¥é…ç½®
```python
# lightrag/api/health.py
from fastapi import APIRouter, HTTPException
from lightrag.kg.shared_storage import StorageManager

router = APIRouter()

@router.get("/health")
async def health_check():
    """åŸºç¡€å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "version": "1.0.0"
    }

@router.get("/health/detailed")
async def detailed_health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥"""
    health_status = {
        "status": "healthy",
        "timestamp": datetime.utcnow().isoformat(),
        "services": {}
    }
    
    # æ£€æŸ¥å­˜å‚¨æœåŠ¡
    storage_manager = StorageManager()
    
    try:
        # Redisè¿æ¥æ£€æŸ¥
        await storage_manager.kv_storage.get("health_check")
        health_status["services"]["redis"] = "healthy"
    except Exception as e:
        health_status["services"]["redis"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    try:
        # PostgreSQLè¿æ¥æ£€æŸ¥
        await storage_manager.vector_storage.health_check()
        health_status["services"]["postgresql"] = "healthy"
    except Exception as e:
        health_status["services"]["postgresql"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    try:
        # Neo4jè¿æ¥æ£€æŸ¥
        await storage_manager.graph_storage.health_check()
        health_status["services"]["neo4j"] = "healthy"
    except Exception as e:
        health_status["services"]["neo4j"] = f"unhealthy: {str(e)}"
        health_status["status"] = "degraded"
    
    return health_status
```

### 2. æ—¥å¿—é…ç½®
```python
# lightrag/utils/logging.py
import logging
import os
from logging.handlers import RotatingFileHandler

def setup_logging():
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    log_level = os.getenv('LOG_LEVEL', 'INFO').upper()
    log_dir = os.getenv('LOG_DIR', './logs')
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    os.makedirs(log_dir, exist_ok=True)
    
    # é…ç½®æ ¹æ—¥å¿—å™¨
    logging.basicConfig(
        level=getattr(logging, log_level),
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            # æ§åˆ¶å°è¾“å‡º
            logging.StreamHandler(),
            # æ–‡ä»¶è¾“å‡º(è½®è½¬)
            RotatingFileHandler(
                os.path.join(log_dir, 'lightrag.log'),
                maxBytes=int(os.getenv('LOG_MAX_BYTES', 52428800)),  # 50MB
                backupCount=int(os.getenv('LOG_BACKUP_COUNT', 10))
            )
        ]
    )
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æµ‹è¯•æ•°æ®éš”ç¦»**: ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®åº“å’Œå­˜å‚¨
2. **æ€§èƒ½åŸºå‡†**: å»ºç«‹æ€§èƒ½åŸºå‡†çº¿ï¼Œç›‘æ§æ€§èƒ½å›å½’
3. **èµ„æºé™åˆ¶**: åœ¨å®¹å™¨ä¸­è®¾ç½®åˆé€‚çš„èµ„æºé™åˆ¶
4. **å®‰å…¨é…ç½®**: ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨å¼ºå¯†ç å’ŒSSLè¯ä¹¦
5. **æ•°æ®å¤‡ä»½**: é…ç½®å®šæœŸæ•°æ®å¤‡ä»½ç­–ç•¥
6. **ç›‘æ§å‘Šè­¦**: è®¾ç½®å…³é”®æŒ‡æ ‡çš„ç›‘æ§å’Œå‘Šè­¦
7. **æ—¥å¿—ç®¡ç†**: é…ç½®æ—¥å¿—è½®è½¬å’Œä¸­å¤®åŒ–æ—¥å¿—æ”¶é›†
---
