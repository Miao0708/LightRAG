# LightRAG 2025å¹´æŠ€æœ¯è¶‹åŠ¿ä¸æœ€ä½³å®è·µ

## ğŸš€ 2025å¹´æŠ€æœ¯å‘å±•è¶‹åŠ¿

### RAGæŠ€æœ¯è¿›åŒ–
- **å¤šæ¨¡æ€RAG**: RAG-Anythingç»Ÿä¸€å¤„ç†æ–‡æœ¬ã€å›¾åƒã€éŸ³è§†é¢‘
- **åŒå±‚æ¬¡æ£€ç´¢**: é«˜çº§å…³é”®è¯(æ¦‚å¿µæ€§) + ä½çº§å…³é”®è¯(å®ä½“æ€§)
- **å›¾è°±+å‘é‡èåˆ**: çŸ¥è¯†å›¾è°±ä¸å‘é‡æ£€ç´¢æ·±åº¦ç»“åˆ
- **å¢å¼ºæ¨ç†èƒ½åŠ›**: ä»æµ…å±‚æ£€ç´¢åˆ°æ·±å±‚æ¨ç†çš„è·ƒå‡

### FastAPI 2025æœ€ä½³å®è·µ

#### æ€§èƒ½ä¼˜åŒ–æ–°æŠ€æœ¯æ ˆ
```python
# 2025å¹´æ¨èçš„é«˜æ€§èƒ½æŠ€æœ¯æ ˆ

# 1. ä½¿ç”¨Polarsæ›¿ä»£pandas (10xæ€§èƒ½æå‡)
import polars as pl
async def process_data(data: list) -> pl.DataFrame:
    df = pl.DataFrame(data)
    return df.lazy().select([
        pl.col("*").fill_null(""),
        pl.col("score").cast(pl.Float64)
    ]).collect()

# 2. httpx + asyncioå¹¶å‘APIè°ƒç”¨
import httpx
import asyncio

async def batch_api_calls(urls: list[str]) -> list[dict]:
    async with httpx.AsyncClient() as client:
        tasks = [client.get(url) for url in urls]
        responses = await asyncio.gather(*tasks)
        return [r.json() for r in responses]

# 3. ä½¿ç”¨tenacityæ™ºèƒ½é‡è¯•
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
async def reliable_api_call(url: str):
    async with httpx.AsyncClient() as client:
        response = await client.get(url, timeout=30)
        response.raise_for_status()
        return response.json()

# 4. ORJSONå¿«é€Ÿåºåˆ—åŒ– (2-3xé€Ÿåº¦æå‡)
import orjson
from fastapi.responses import ORJSONResponse

@app.get("/fast-json", response_class=ORJSONResponse)
async def fast_json_response():
    return {"data": large_data_structure}
```

#### FastAPIå¼‚æ­¥æœ€ä½³å®è·µ (2025ç‰ˆ)
```python
from fastapi import FastAPI, BackgroundTasks, Depends
import asyncio
from contextlib import asynccontextmanager

# åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
@asynccontextmanager
async def lifespan(app: FastAPI):
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    await init_connections()
    yield
    # å…³é—­æ—¶æ¸…ç†
    await cleanup_connections()

app = FastAPI(lifespan=lifespan)

# é«˜æ€§èƒ½è·¯ç”±è®¾è®¡
@app.get("/")
async def read_root():
    """çº¯å¼‚æ­¥è·¯ç”± - æ¨èç”¨æ³•"""
    return {"Hello": "World"}

@app.post("/process")
async def process_data(
    data: dict,
    background_tasks: BackgroundTasks
):
    """ä¸»è¦ä»»åŠ¡å¼‚æ­¥å¤„ç†ï¼Œåå°ä»»åŠ¡å¹¶è¡Œ"""
    # ä¸»è¦å¤„ç†é€»è¾‘
    result = await main_processing(data)
    
    # åå°ä»»åŠ¡ä¸é˜»å¡å“åº”
    background_tasks.add_task(log_processing, data, result)
    
    return {"result": result}

# ä¾èµ–æ³¨å…¥ä¼˜åŒ–
async def get_db_session():
    async with db_pool.acquire() as conn:
        yield conn

@app.get("/users/{user_id}")
async def get_user(
    user_id: int,
    db = Depends(get_db_session)
):
    return await db.fetch_one("SELECT * FROM users WHERE id = $1", user_id)
```

### React + TypeScript 2025æ–°æ ‡å‡†

#### Vite 7 + React 19é…ç½®
```json
// package.json - 2025æ¨èé…ç½®
{
  "name": "lightrag-webui",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "test": "vitest",
    "test:ui": "vitest --ui"
  },
  "dependencies": {
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "typescript": "^5.6.0",
    "@tanstack/react-query": "^5.0.0",
    "zustand": "^5.0.0",
    "tailwindcss": "^3.4.0"
  },
  "devDependencies": {
    "vite": "^7.0.0",
    "vitest": "^2.0.0",
    "@testing-library/react": "^16.0.0"
  }
}
```

```typescript
// vite.config.ts - 2025ä¼˜åŒ–é…ç½®
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

export default defineConfig({
  plugins: [react()],
  build: {
    target: 'esnext',
    minify: 'esbuild',
    rollupOptions: {
      output: {
        manualChunks: {
          vendor: ['react', 'react-dom'],
          ui: ['@radix-ui/react-dialog', '@radix-ui/react-toast']
        }
      }
    }
  },
  server: {
    port: 3000,
    host: true
  }
})
```

#### React 19æ–°ç‰¹æ€§åº”ç”¨
```typescript
// ä½¿ç”¨React 19çš„æ–°ç‰¹æ€§
import { use, useOptimistic, useFormStatus } from 'react'

// 1. use() Hookæ›¿ä»£useEffectæ•°æ®è·å–
function UserProfile({ userId }: { userId: string }) {
  const user = use(fetchUser(userId)) // ç›´æ¥ä½¿ç”¨Promise
  
  return <div>{user.name}</div>
}

// 2. useOptimisticä¹è§‚æ›´æ–°
function TodoList() {
  const [todos, setTodos] = useState([])
  const [optimisticTodos, addOptimisticTodo] = useOptimistic(
    todos,
    (state, newTodo) => [...state, newTodo]
  )
  
  async function addTodo(formData: FormData) {
    const newTodo = { id: Date.now(), text: formData.get('text') }
    addOptimisticTodo(newTodo)
    
    try {
      await fetch('/api/todos', {
        method: 'POST',
        body: JSON.stringify(newTodo)
      })
      setTodos([...todos, newTodo])
    } catch (error) {
      // è‡ªåŠ¨å›æ»šä¹è§‚æ›´æ–°
    }
  }
  
  return (
    <form action={addTodo}>
      {optimisticTodos.map(todo => (
        <div key={todo.id}>{todo.text}</div>
      ))}
      <input name="text" />
      <SubmitButton />
    </form>
  )
}

// 3. useFormStatusè¡¨å•çŠ¶æ€
function SubmitButton() {
  const { pending } = useFormStatus()
  
  return (
    <button type="submit" disabled={pending}>
      {pending ? 'æäº¤ä¸­...' : 'æäº¤'}
    </button>
  )
}
```

## ğŸ“¦ ä¸‰æ–¹æ¨¡å—æœ€ä½³å®è·µ (2025ç‰ˆ)

### FastAPIé«˜çº§é…ç½®
```python
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.gzip import GZipMiddleware
import uvloop  # æ€§èƒ½æå‡2-4x

# ä½¿ç”¨uvloopæå‡äº‹ä»¶å¾ªç¯æ€§èƒ½
uvloop.install()

app = FastAPI(
    title="LightRAG API",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json"
)

# ä¸­é—´ä»¶é…ç½® (2025æ¨è)
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½² (2025æœ€ä½³å®è·µ)
"""
# ä½¿ç”¨Gunicorn + Uvicorn workers
gunicorn lightrag.api.lightrag_server:app \
    -w 4 \
    -k uvicorn.workers.UvicornWorker \
    --bind 0.0.0.0:9621 \
    --timeout 240 \
    --keepalive 2 \
    --max-requests 1000 \
    --max-requests-jitter 100
"""
```

### Rediså¼‚æ­¥è¿æ¥æ± æœ€ä½³å®è·µ
```python
import redis.asyncio as redis
from typing import Optional
import asyncio

class RedisManager:
    def __init__(self):
        self.pool: Optional[redis.ConnectionPool] = None
        self.client: Optional[redis.Redis] = None
    
    async def init_connection(self):
        """åˆå§‹åŒ–Redisè¿æ¥æ±  - 2025æœ€ä½³é…ç½®"""
        self.pool = redis.ConnectionPool.from_url(
            "redis://localhost:6379/0",
            max_connections=30,          # è¿æ¥æ± å¤§å°
            socket_connect_timeout=5,    # è¿æ¥è¶…æ—¶
            socket_timeout=30,           # æ“ä½œè¶…æ—¶
            retry_on_timeout=True,       # è¶…æ—¶é‡è¯•
            health_check_interval=30,    # å¥åº·æ£€æŸ¥
            encoding='utf-8',
            decode_responses=True
        )
        self.client = redis.Redis.from_pool(self.pool)
    
    async def close_connection(self):
        """æ­£ç¡®å…³é—­è¿æ¥"""
        if self.client:
            await self.client.aclose()
        if self.pool:
            await self.pool.aclose()
    
    async def get_client(self) -> redis.Redis:
        """è·å–Rediså®¢æˆ·ç«¯"""
        if not self.client:
            await self.init_connection()
        return self.client

# å…¨å±€Redisç®¡ç†å™¨
redis_manager = RedisManager()

# ä½¿ç”¨ç¤ºä¾‹
async def cache_data(key: str, data: dict, expire: int = 3600):
    client = await redis_manager.get_client()
    await client.set(key, json.dumps(data), ex=expire)

async def get_cached_data(key: str) -> Optional[dict]:
    client = await redis_manager.get_client()
    data = await client.get(key)
    return json.loads(data) if data else None
```

### PostgreSQL + pgvectorå¼‚æ­¥æ“ä½œ
```python
import asyncpg
import numpy as np
from typing import List, Tuple

class PGVectorManager:
    def __init__(self):
        self.pool: Optional[asyncpg.Pool] = None
    
    async def init_pool(self):
        """åˆå§‹åŒ–PostgreSQLè¿æ¥æ±  - 2025ä¼˜åŒ–é…ç½®"""
        self.pool = await asyncpg.create_pool(
            host="localhost",
            port=5432,
            user="postgres",
            password="password", 
            database="lightrag_db",
            min_size=5,
            max_size=30,
            command_timeout=60,
            server_settings={
                'jit': 'off',                    # ç¦ç”¨JITä»¥æå‡å°æŸ¥è¯¢æ€§èƒ½
                'shared_preload_libraries': 'pg_stat_statements',
                'max_connections': '200'
            }
        )
        
        # åˆ›å»ºå‘é‡è¡¨å’Œç´¢å¼•
        async with self.pool.acquire() as conn:
            await conn.execute("""
                CREATE EXTENSION IF NOT EXISTS vector;
                
                CREATE TABLE IF NOT EXISTS embeddings (
                    id SERIAL PRIMARY KEY,
                    content TEXT NOT NULL,
                    embedding vector(1024),
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT NOW()
                );
                
                CREATE INDEX IF NOT EXISTS embeddings_vector_idx 
                ON embeddings USING ivfflat (embedding vector_cosine_ops) 
                WITH (lists = 100);
            """)
    
    async def upsert_embeddings(
        self, 
        data: List[Tuple[str, np.ndarray, dict]]
    ):
        """æ‰¹é‡æ’å…¥å‘é‡æ•°æ®"""
        async with self.pool.acquire() as conn:
            await conn.executemany("""
                INSERT INTO embeddings (content, embedding, metadata)
                VALUES ($1, $2, $3)
                ON CONFLICT (id) DO UPDATE SET
                    content = EXCLUDED.content,
                    embedding = EXCLUDED.embedding,
                    metadata = EXCLUDED.metadata
            """, [
                (content, embedding.tolist(), metadata)
                for content, embedding, metadata in data
            ])
    
    async def similarity_search(
        self, 
        query_vector: np.ndarray, 
        top_k: int = 10,
        threshold: float = 0.7
    ) -> List[dict]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢ - ä¼˜åŒ–ç‰ˆ"""
        async with self.pool.acquire() as conn:
            # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
            rows = await conn.fetch("""
                SELECT id, content, metadata, 
                       1 - (embedding <=> $1::vector) as similarity
                FROM embeddings
                WHERE 1 - (embedding <=> $1::vector) > $2
                ORDER BY embedding <=> $1::vector
                LIMIT $3
            """, query_vector.tolist(), threshold, top_k)
            
            return [dict(row) for row in rows]

# å…¨å±€PGç®¡ç†å™¨
pg_manager = PGVectorManager()
```

## ğŸ”¥ æ€§èƒ½ç›‘æ§ä¸è°ƒè¯• (2025ç‰ˆ)

### py-spyç”Ÿäº§ç¯å¢ƒæ€§èƒ½åˆ†æ
```bash
# å®æ—¶æ€§èƒ½ç›‘æ§
py-spy top --pid <fastapi_worker_pid>

# ç”Ÿæˆç«ç„°å›¾
py-spy record -o profile.svg --pid <fastapi_worker_pid> --duration 60

# å†…å­˜ä½¿ç”¨åˆ†æ
py-spy dump --pid <fastapi_worker_pid>
```

### è‡ªåŠ¨åŒ–æµ‹è¯•æœ€ä½³å®è·µ
```python
# ä½¿ç”¨pytest + httpxè¿›è¡ŒAPIæµ‹è¯•
import pytest
import httpx
from fastapi.testclient import TestClient

@pytest.mark.asyncio
async def test_query_performance():
    """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½åŸºå‡†"""
    async with httpx.AsyncClient(app=app, base_url="http://test") as ac:
        start_time = time.time()
        
        response = await ac.post("/query", json={
            "query": "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "mode": "hybrid",
            "enable_rerank": True
        })
        
        end_time = time.time()
        
        assert response.status_code == 200
        assert (end_time - start_time) < 2.0  # æ€§èƒ½è¦æ±‚ï¼š2ç§’å†…å“åº”
        
        data = response.json()
        assert "result" in data
        assert len(data["result"]) > 0

# Vitestå‰ç«¯æµ‹è¯•
"""
// vitest.config.ts
import { defineConfig } from 'vitest/config'

export default defineConfig({
  test: {
    environment: 'jsdom',
    globals: true,
    setupFiles: ['./src/test/setup.ts']
  }
})
"""
```

## ğŸš€ éƒ¨ç½²ä¼˜åŒ– (2025ç‰ˆ)

### Dockerå¤šé˜¶æ®µæ„å»ºä¼˜åŒ–
```dockerfile
# 2025å¹´Dockeræœ€ä½³å®è·µ
FROM node:20-alpine AS frontend-builder
WORKDIR /app/frontend
COPY lightrag_webui/package*.json ./
RUN npm ci --only=production
COPY lightrag_webui/ ./
RUN npm run build

FROM python:3.12-slim AS backend-builder
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

FROM python:3.12-slim AS runtime
WORKDIR /app

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
COPY --from=backend-builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages
COPY --from=backend-builder /usr/local/bin /usr/local/bin

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY lightrag/ ./lightrag/
COPY --from=frontend-builder /app/frontend/dist ./lightrag/api/webui/

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV PYTHONUNBUFFERED=1

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:9621/health || exit 1

# érootç”¨æˆ·è¿è¡Œ
RUN useradd --create-home --shell /bin/bash lightrag
USER lightrag

EXPOSE 9621
CMD ["uvicorn", "lightrag.api.lightrag_server:app", "--host", "0.0.0.0", "--port", "9621", "--workers", "4"]
```

## ğŸ’¡ å…³é”®è¦ç‚¹æ€»ç»“

1. **FastAPIæ€§èƒ½**: å¼‚æ­¥ä¼˜å…ˆï¼Œä½¿ç”¨uvloopï¼ŒORJSONåºåˆ—åŒ–
2. **æ•°æ®å¤„ç†**: Polarsæ›¿ä»£pandasï¼Œhttpxå¹¶å‘è°ƒç”¨
3. **å‰ç«¯æŠ€æœ¯**: React 19 + Vite 7ï¼Œæ·˜æ±°CRA
4. **æ•°æ®åº“è¿æ¥**: è¿æ¥æ± ç®¡ç†ï¼Œå¼‚æ­¥æ“ä½œï¼Œæ‰¹é‡å¤„ç†
5. **ç›‘æ§è°ƒè¯•**: py-spyæ€§èƒ½åˆ†æï¼Œè‡ªåŠ¨åŒ–æµ‹è¯•
6. **éƒ¨ç½²ä¼˜åŒ–**: å¤šé˜¶æ®µDockeræ„å»ºï¼Œå¥åº·æ£€æŸ¥

è¿™äº›2025å¹´çš„æœ€æ–°æŠ€æœ¯æ ˆå°†æ˜¾è‘—æå‡LightRAGé¡¹ç›®çš„æ€§èƒ½å’Œå¼€å‘ä½“éªŒï¼
description:
globs:
alwaysApply: false
---
